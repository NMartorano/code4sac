---
title: 'Code4Sac: 311 Service Call Data Analysis'
output:
  html_document:
    toc: true
---

Author: Walter Yu  
Organization: Code for Sacramento  

# Introduction

Code for Sacramento is develop a neighborhood portal application; as a result, this notebook evaluates the City of Sacramento 311 service call dataset for insights and trends which may be helpful in developing useful features. This notebook will focus on an initial analysis and identifying potential issues related to users and their neighborhoods.  

Conjecture:  

Per discussion with City of Sacramento staff, 311 service calls are a relatively stable source for identify potential issues/needs of neighborhoods. Included are time and location data which will be useful for identifying trends.  

# Findings:  

1. Conventional statistical and machine learning methods were not a good fit for analyzing service call data due to its highly categorial nature; almost all variables were categorical with exception of time/location data.  
2. Exploratory data analysis and logistic regression were used to confirm this finding; spatial analysis was used to yield better results.  
3. Clustering and density plots were developed in the GeoDa software application to identify natural concentrations of service calls by zipcode.  

Methodology:  

1. Exploratory data analysis (EDA) and model fits showed that spatial and temporal analysis would be more appropriate methods of analysis.  
2. As a result, spatial analysis with R and GeoDa were used to identify trends.  
3. Findings are documented within the notebook; additional analysis was completed in GeoDa.  

Dataset:  

311 service call dataset from City of Sacramento; summary statistics for the full and partial datasets are listed below. The data is available in geospatial, tabular or API format; the tabular format is used for this analysis to identify important neighborhoods and trends which are relevant to developing the application.  

City of Sacramento 311 Service Call Dataset: https://data.cityofsacramento.org/datasets/08794a6695b3483f889e9bef122517e9_0  

Citations:  
1. HES CSCI E-63c: https://www.extension.harvard.edu/course-catalog/courses/elements-of-data-science-and-statistical-learning-with-r/15123  
2. ISLR Textbook: https://www-bcf.usc.edu/~gareth/ISL/  
3. ESLR Textbook: https://web.stanford.edu/~hastie/ElemStatLearn/  

Notes:  
1. All sources are cited accordingly.  
2. Source dataset is ~1.2M rows, so not included in this repository.  
3. As a result, please review attached HTML file for analysis/findings.  

** P0 **  
** P0 **  
** P0 **  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Install packages with rcran:
# install.packages("ggcorrplot")
# install.packages("dplyr")

library(dplyr)
library(readr)
library(stringr)
library(ggplot2)
library(ggcorrplot)
library(gridExtra)
library(leaps)
library(glmnet)
library(reshape2)
library(randomForest)
library(e1071)
library(FNN)

# LDA/QDA Packages:
library(boot)
library(MASS)
library(class)
library(reshape2)

# Neural Net Packages:
library(neuralnet)
library(tidyr)

# Spatial Packages:
library(maptools)

# install devtools/rspatial:
# install.packages("devtools")
library(devtools)

# Install packages with github:
# devtools::install_github("rspatial/rspatial")
# library(rspatial)

```

** P1 **  
** P1 **  
** P1 **  

# Part 1A - Summary Statistics  

References:  
1. HES CSCI-E63c Midterm, HW9, HW10, HW11 code  
2. ISLR p.28; categorical variables  

Steps:  
1. Import data, evaluate dimensions with dim() and str() functions  
2. Subset first 5k rows to reduce runtime    
3. Subset columns to only include relevant data (time, location, type)  
4. Verify subset with summary statistics; dim, str and summary functions  

Observations:  
1. Dataset consists of categorical variables and time/location data  
2. Most categorical have multiple levels; some have many (e.g. category level)  
3. Time data recorded as timestamps; locations in lat/long coordinates  
4. Call category, time and location data appear most relevant  
5. As a result, those variables were extracted as a subset  

Data Manipulation:  
1. Original dataset = ~1.2M rows x 27 columns  
2. Reduced dataset = 5k rows x 27 columns  
3. Test dataset may be extracted from full dataset  
4. Convert categorical variables as factors to facilitate logistic regression  
5. Factors will be converted to numeric values to facilitate analysis

```{r p1.1}

# import data
train_data <- read.table(
  '311_Calls_OSC_View.csv',
  sep=',',
  header=TRUE,
  quote='',
  strip.white=TRUE,
  na.strings='?'
)

# extract first 5k rows for smaller training dataset:
train_reduced = train_data[1:5000,]
write.csv(train_reduced, file = "train_5k.csv")

# verify dim:
dim(train_reduced)

```

Data Attributes:  

$ X                    : num  
$ Y                    : num  
$ OBJECTID             : int  
$ ReferenceNumber      : Factor w/ 1130759 levels  
$ CategoryHierarchy    : Factor w/ 437 levels  
$ CategoryLevel1       : Factor w/ 18 levels  
$ CategoryLevel2       : Factor w/ 48 levels  
$ CategoryLevel3       : Factor w/ 10 levels  
$ CategoryLevel4       : logi  
$ CategoryLevel5       : logi  
$ CategoryName         : Factor w/ 286 levels  
$ CouncilDistrictNumber: int  
$ SourceLevel1         : Factor w/ 5 levels  
$ Neighborhood         : Factor w/ 130 levels  
$ DateCreated          : Factor w/ 1118207 levels  
$ DateUpdated          : Factor w/ 927449 levels  
$ DateClosed           : Factor w/ 772674 levels  
$ StatusType           : Factor w/ 14 levels  
$ SystemId             : int  
$ ServiceLevelName     : Factor w/ 34 levels  
$ Latitude             : num  
$ Longitude            : num  
$ XCoord               : num  
$ YCoord               : num  
$ CrossStreet          : Factor w/ 11685 levels  
$ GlobalID             : Factor w/ 1225340 levels  
$ ZIP                  : Factor w/ 66 levels  

```{r p1.2}

# reduce to smaller sample size for relevant data:
train_col = train_reduced[, c(
  # "X",
  # "Y",
  "CategoryHierarchy",
  "CategoryName",
  "CategoryLevel1",
  "CategoryLevel2",
  "CategoryLevel3",
  "CouncilDistrictNumber",
  "SourceLevel1",
  "Neighborhood",
  "DateCreated",
  "DateUpdated",
  "DateClosed",
  "StatusType",
  "ServiceLevelName",
  "Latitude",
  "Longitude",
  "XCoord",
  "YCoord",
  "ZIP"
)]

# verify dim and drop NA; train_data:
# which(is.na(train_col))
# dim(train_col)
# train_col = na.omit(train_col)
# dim(train_col)

# EDA output; train_data:
# summary(train_col)
dim(train_col)
str(train_col)

# Encode categorial variables as factors:
# https://stats.idre.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/

# Selected columns for relevant data:
# "CategoryHierarchy",
# "CategoryName",
# "CategoryLevel1",
# "CategoryLevel2",
# "CategoryLevel3",
# "CouncilDistrictNumber",
# "SourceLevel1",
# "Neighborhood",
# "StatusType",
# "ServiceLevelName",
# "ZIP"

train_col$cat_heir.f <- factor(train_col$CategoryHierarchy)
is.factor(train_col$cat_heir.f)

train_col$cat_name.f <- factor(train_col$CategoryName)
is.factor(train_col$cat_name.f)

train_col$cat_1.f <- factor(train_col$CategoryLevel1)
is.factor(train_col$cat_1.f)

train_col$cat_2.f <- factor(train_col$CategoryLevel2)
is.factor(train_col$cat_2.f)

train_col$cat_3.f <- factor(train_col$CategoryLevel3)
is.factor(train_col$cat_3.f)

train_col$district.f <- factor(train_col$CouncilDistrictNumber)
is.factor(train_col$district.f)

train_col$source.f <- factor(train_col$SourceLevel1)
is.factor(train_col$source.f)

train_col$neighborhood.f <- factor(train_col$Neighborhood)
is.factor(train_col$neighborhood.f)

train_col$status.f <- factor(train_col$StatusType)
is.factor(train_col$status.f)

train_col$service.f <- factor(train_col$ServiceLevelName)
is.factor(train_col$service.f)

train_col$zip.f <- factor(train_col$ZIP)
is.factor(train_col$zip.f)

# convert into numeric values:
# train_col_numeric = train_col
# train_col_numeric %>% mutate_if(is.factor, as.numeric)

# convert with lapply function:
# https://stackoverflow.com/questions/47922184/convert-categorical-variables-to-numeric-in-r

train_col_numeric = train_col
i <- sapply(train_col_numeric, is.factor)
train_col_numeric[i] <- lapply(train_col_numeric[i], as.numeric)

# verify columns as numeric:
# str(train_col_numeric)
# head(train_col_numeric, 5)

# summary statistics for numeric values
# summary(train_col_numeric)
dim(train_col_numeric)
str(train_col_numeric)

```

References:  
1. HES CSCI-E63c HW2 code  
2. https://en.wikipedia.org/wiki/Pearson_correlation_coefficient  
3. https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient  

Steps:  
1. Calculate correlation and create correlation plot   
2. Plots for Pearson and Spearman correlation methods  
3. Document observations below  

Observations:  
1. Pearson coefficient (ranges between 0 and 1) is a measure of LINEAR correlation; plots showed relatively low correlation between most variables  
2. Spearman coefficient (measured between 0 and 1) indicates MONOTONIC (linear or not) correlation; plots showed relative low correlation between most variables  
3. Although entire variables may have low correlation, there may be individual trends between variables which will be explored in the following sections  

```{r p1.2B, fig.height = 8, fig.width = 8, fig.align = "center"}

# create correlation plot:
corr <- round(cor(train_col_numeric, method="pearson", use="everything"), 4)
ggcorrplot(corr, title="Correlation Plot - Pearson (Linear)")

```

```{r p1.2C, fig.height = 8, fig.width = 8, fig.align = "center"}

# create correlation plot:
corr <- round(cor(train_col_numeric, method="spearman", use="everything"), 4)
ggcorrplot(corr, title="Correlation Plot - Spearman (Non-Linear/Monotonic)")

```

References:  
1. HES CSCI-E63c Midterm, HW5 code  
2. ISLR p.67; p-value  

Steps:  
1. Create histogram to evaluate distribution of frequency/district   
2. Create stacked bar histograms for service level and district  
3. Evaluate trends from plots; identify possible trends  
4. Create plots for significant factors based on p-values  
5. Document observations below  

Observations:  
1. Categorical variables provide limited use for histogram plots since they are intended for continuous/numeric variables  
2. However, call frequency by district number histogram showed distribution while the other plots/variables did not convert well or translate into coherent plots  

```{r p1.3}

# Create historgram to evaluate distribution:
hist(
  train_col_numeric$district.f,
  main='Council District',
  col='purple',
  xlab='Continuous Variable - Council District',
  breaks=30
)

hist(
  train_col_numeric$service.f,
  main='311 Service Level',
  col='purple',
  xlab='Continuous Variable - 311 Service Level',
  breaks=10
)

```

References:  
1. Spatial plot: https://rspatial.org/rosu/Chapter5.html  
2. R Spatial Textbook: https://rspatial.org/rosu/ROSU.pdf  

Steps:  
1. Develop spatial analysis plots below to identify trends  

Observations:  
1. Since variables do not appear to have strong correlations and EDA shows that most variables only have an association for individual values/levels  
2. As a result, explore other analytical methods to identify trends; primarily, time series and geospatial analysis  

```{r p1.3A, fig.height = 6, fig.width = 12, fig.align = "center", eval=FALSE}

# verify data dimensions/columns:
# str(train_col)
# dim(train_col)

# plot service call data on world map:
plot(train_col[,15:14], cex=0.5, col='red')

## Checking rgeos availability: TRUE
data(wrld_simpl)
plot(wrld_simpl, add=TRUE)

```

```{r p1.3B, fig.height = 8, fig.width = 8, fig.align = "center", eval=FALSE}

# plot service call data on state map:
counties <- sp_data('counties')
plot(counties)
points(train_col[,c('Longitude', 'Latitude')], col='blue', pch=20)

```

```{r p1.3C}

# load rspatial if needed:
if (!require("rspatial")) devtools::install_github('rspatial/rspatial')
library(rspatial)

# test plot by county:
# yolo <- counties[counties$NAME == 'Yolo', ]
# plot(yolo, col='light gray', border='gray')

# organize service calls by category type:
tb <- sort(table(train_col$CategoryLevel1))[-1]
tb

# duplicate training data for manipulation:
train_xy <- train_col

# extract lag/long and convert to coordinates:
# xy <- train_xy[,15:14]
# coordinates(xy)

# extract lag/long and convert to coordinates:
# xy <- train_xy[,c('XCoord', 'YCoord')]
xy <- train_xy[,c('Longitude', 'Latitude')]
dim(xy)

# remove duplications and verify dimensions:
xy <- unique(xy)
dim(xy)

# calculate mean center
mc <- apply(xy, 2, mean)
# calculate standard distance
sd <- sqrt(sum((xy[,1] - mc[1])^2 + (xy[,2] - mc[2])^2) / nrow(xy))

```

```{r p1.3D, fig.height = 8, fig.width = 8, fig.align = "center"}

# plot county:
counties <- sp_data('counties')
county <- counties[counties$NAME == 'Sacramento', ]
plot(county)

# plot points:
points(train_xy[,c('Longitude', 'Latitude')], col='blue', pch=20)
# points(xy, cex=.5)

points(cbind(mc[1], mc[2]), pch='*', col='red', cex=5)
# make a circle
bearing <- 1:360 * pi/180
cx <- mc[1] + sd * cos(bearing)
cy <- mc[2] + sd * sin(bearing)
circle <- cbind(cx, cy)
lines(circle, col='red', lwd=2)

```

References:  
1. HES CSCI-E63c Lecture 1, 3 notes; chi-squared test  
2. ISLR p.67; p-value and significance  

Steps:  
1. Calculate chi-squared test for categorical variables  
2. Evaluate/analyze results  
3. Document observations below  

Observations:  
1. Chi-squared test shows low p-values for categorial variables  
2. T-test for continuous variables; not as effective  
3. Create plots for significant factors based on p-values  

```{r p1.5, eval=FALSE}

# Chi-Squared test for continuous variables:
t.test(
  as.numeric(train_col$neighborhood.f),
  train_data$service.f
)

# Chi-Squared test for categorical variables:
chisq.test(
  table(
    train_col$neighborhood.f,
    train_col$cat_1.f
  )
)

```

References:  
1. HES CSCI-E63c Midterm, HW6; PCA model  
2. ISLR p.230; PCA components  
3. ISLR p.233; PCA components  

Steps:  
1. Verify/prepare data for PCA plots; use dummy variables to setup factors  
2. Scale/fit data for PCA plots; plot for top contributors to variance  
3. Evaluate top contributors to variance  
4. Plot variance by first several PCA  

Observations:  
1. Use dummy variables to address muiple variable levels prior to PCA plot  
2. PCA calculations show top contributors of variance to the model  
3. PCA plot show interaction between neighborhood and service level  
4. However, categorical variables did not translate well to continuous  
5. As a result, PCA calculates did not identify any useful trends  

```{r p1.6}

# train_scaled = train_data %>% mutate_if(is.numeric, scale)
# train_dummy = model.matrix(noyes ~., train_scaled)[,-1]

# Scale/dummy data prior to plot:
# train_numeric = as.numeric(train_col$zip.f)
# train_scaled = train_numeric %>% mutate_if(is.numeric, scale)
# train_dummy = model.matrix(noyes ~., train_scaled)[,-1]

# Scale/dummy data prior to plot:
train_scaled = train_col_numeric %>% mutate_if(is.numeric, scale)
train_dummy = model.matrix(Neighborhood ~., train_scaled)[,-1]

# prepare PCA components for plot:
prcomp_plot = prcomp(train_dummy)
plot(
  prcomp_plot,
  xlab='dimensions',
  col='purple'
)

# calculate top five PCA components:
sort(abs(prcomp_plot$rotation[,1]), decreasing=TRUE)[1]
sort(abs(prcomp_plot$rotation[,2]), decreasing=TRUE)[1]
sort(abs(prcomp_plot$rotation[,3]), decreasing=TRUE)[1]
sort(abs(prcomp_plot$rotation[,4]), decreasing=TRUE)[1]
sort(abs(prcomp_plot$rotation[,5]), decreasing=TRUE)[1]

# create biplot of PCA components:
biplot(
  prcomp_plot,
  pc.biplot=TRUE,
  xlabs=rep('*', dim(prcomp_plot$x)[1]),
  col=c('red','purple')
)

# create PCA plot:
plot(
  prcomp_plot$x[,1:2],
  main='PCA Plot: Neighborhood and Service Level',
  col=c(ifelse(train_col_numeric$Neighborhood== '>=10', 'red', 'purple')),
  cex=1.0,
  pch=ifelse(train_col_numeric$ServiceLevelName== '>=1', '*', '+')
)

```

References:  
1. ISLR p.67; p-value and significance  
2. ISLR p.286; logistic regression  
3. ISLR p.291; logistic regression usage  

Steps:  
1. Fit logistic regression model for predictor variables  
2. Evaluate/compare results of each variable  
3. Specifically, evaluate p-values of logistic regression output  
4. Evaluate results for association between predictor/outcome  

Observations:  
1. Most variables did not have low p-values, indicating poor model fit  
2. However, some variables did show significance  
3. Specifiically, some neighborhoods show relationship with particular call categories  

```{r p1.7}

# LR model fit:

glm_train = glm(
  CategoryLevel1~neighborhood.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel1~district.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel1~zip.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel2~neighborhood.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel2~district.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel2~zip.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel3~neighborhood.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel3~district.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  CategoryLevel3~zip.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  Neighborhood~cat_1.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  Neighborhood~cat_2.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  Neighborhood~cat_3.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  Neighborhood~service.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  Neighborhood~source.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  ZIP~cat_1.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  ZIP~cat_2.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  ZIP~cat_3.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  ZIP~service.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

glm_train = glm(
  ZIP~source.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

```

# Part 2 - Best Variable Subset Selection  

References:  
1. HES CSCI-E63c Midterm, HW5  
2. Midterm-P2 and HW5; best subset variable selection  
3. ISLR p.244; best subset selection  
4. ISLR p.247; best subset selection  

Steps:  
1. Use variable selection to identify best predictors  
2. Use forward, backward and seq replacement methods  
3. Create metrics plot and individual plot for each method  
4. Evaluate/compare plot results  
5. Document observations below  

Observations:  
1. Each method returned similar variables and order of selection  
2. Results confirm previous findings/analysis/conjecture  
3. Neighborhood variable showed some association with call category  

```{r p2.2}

# helper function for best subset selection:
summaryMetrics <- NULL
whichAll <- list()
my_methods = c('backward', 'forward', 'seqrep')

for ( myMthd in my_methods ) {
  method_metrics = NULL
  rsRes <- regsubsets(
    Neighborhood~.,
    train_scaled,
    method=myMthd,
    nvmax=ncol(train_scaled)-1
  )
  summRes <- summary(rsRes)
  whichAll[[myMthd]] <- summRes$which

  for ( metricName in c('rsq','rss','adjr2','cp','bic') ) {
    summaryMetrics <- rbind(summaryMetrics,
      data.frame(method=myMthd,metric=metricName,
      nvars=1:length(summRes[[metricName]]),
      value=summRes[[metricName]]))
    method_metrics = rbind(method_metrics,
      data.frame(method=myMthd,metric=metricName,
      nvars=1:length(summRes[[metricName]]),
      value=summRes[[metricName]]))
  }
}

# plot best subset:
ggplot(
    summaryMetrics,
    aes(x=nvars,y=value,shape=method,colour=method)
) + geom_path() + geom_point() + facet_wrap(~metric,scales='free') + theme(legend.position='top')

# plot best subset:
old.par <- par(mfrow=c(1,1),ps=9,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
  image(1:nrow(whichAll[[myMthd]]),
        1:ncol(whichAll[[myMthd]]),
        whichAll[[myMthd]],xlab="N(vars)",ylab="",
        xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
        col=c("white","purple"),main=myMthd)
  axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
  axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}

```

# Recommendations  

The objective of this study was to identify trends for developing useful features into the Portal application; as a result the follow recommendations are provided based on results of statistical and spatial analysis:  

1. Service Call Clusters - Service calls were grouped into the downtown, Pocket and Natomas neighborhoods; as a result, these areas are recommended as focus areas to organize neighborhoods followed by the other groups observed in the spatial analysis plots.  
2. Service Call Categories - Solid waste, trash and dumping-related calls were the majority of calls; as a result, this should be an areas of focus for communities when providing them support of their issues.  

# Conclusion  

1. Summary statistics revealed that most variables with categorical; neighborhood/location data is of particular interest and would be useful for developing application features.  
2. Time/location data will be used for additional analysis (time series/spatial analysis).  
3. Categorical variable conversion was not as successful as expected; variables did not translate to good model fit.  
