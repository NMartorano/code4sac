---
title: 'Code4Sac: 311 Service Call Data Analysis'
output:
  html_document:
    toc: true
---

Author: Walter Yu  
Organization: Code for Sacramento  
  
# Introduction
     
Code for Sarcramento is develop a neighborhood portal application; as a result, this notebook evaluates the City of Sacramento 311 service call dataset for insights and trends which may be helpful in developing useful features.  
    
This notebook will focus on an initial analysis and modeling effort with additional prediction to follow as more information is available regarding the application.  
  
Dataset:
  
311 service call dataset from City of Sacramento; summary statistics for the full and partial datasets are listed below. The data is available in geospatial, tabular or API format; the tabular format is used for this analysis to identify important neighorhoods and trends which are relevant to developing the application.  

City of Sacramento 311 Service Call Dataset: https://data.cityofsacramento.org/datasets/08794a6695b3483f889e9bef122517e9_0  

Notes:  
1. All sources are cited accordingly.  
2. Source dataset is ~1.2M rows, so not included in this repository.  
3. As a result, please review attached HTML file for analysis/findings.  
  
** P0 **  
** P0 **  
** P0 **  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Install any necessary packages:
# install.packages("FNN")

library(dplyr)
library(readr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(leaps)
library(glmnet)
library(reshape2)
library(randomForest)
library(e1071)
library(FNN)

# LDA/QDA:
library(boot)
library(MASS)
library(class)
library(reshape2)

# Neural Net:
library(neuralnet)
library(tidyr)

```

** P1 **  
** P1 **  
** P1 **  

# Part 1A - Summary Statistics  

References:  
1. HES CSCI-E63c Midterm, HW9, HW10, HW11 code  
2. ISLR p.28; categorical variables  

Steps:  
1. Import data, evaluate dimensions  
2. Subset first 5k rows to reduce runtime  
3. Subset columns to only include relevant data  
4. Verify subset with summary statistics; dim, str and summary functions  

Observations:  
1. Import dataset; includes header so note so in read.table  
2. Use str() function to evaluate factors/variables  
3. Original dataset = ~1.2M rows x 27 columns  
4. Resulting dataset = 5k rows x 27 columns  
5. Test dataset may be extracted from full dataset  

```{r p1.1}

# import train_data:
train_data <- read.table(
  '311_Calls_OSC_View.csv',
  sep=',',
  header=TRUE,
  quote='',
  strip.white=TRUE,
  na.strings='?'
)

```

```{r p1.2}

# verify dim and drop NA; train_data:
dim(train_data)

# reduce to smaller sample size to reduce runtime:
train_reduced = train_data[1:5000,]

# reduce to smaller sample size for relevant data:
train_col = train_reduced[, c(
  "CategoryHierarchy",
  "CategoryName",
  "CategoryLevel1",
  "CategoryLevel2",
  "CategoryLevel3",
  "CouncilDistrictNumber",
  "SourceLevel1",
  "Neighborhood",
  "StatusType",
  "ServiceLevelName",
  "ZIP"
)]

cat("\n")
cat("*** remove na null values ***")
cat("\n")

# verify dim and drop NA; train_data:
# which(is.na(train_col))
# dim(train_col)
# train_col = na.omit(train_col)
# dim(train_col)

cat("\n")
cat("*** output summary; train_data ***")
cat("\n")

# EDA; train_data:
dim(train_col)
str(train_col)
summary(train_col)

cat("\n")
cat("*** encode categorical variables as factors ***")
cat("\n")

# Encode categorial variables as factors:
# https://stats.idre.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/

# Selected columns for relevant data:
# "CategoryHierarchy",
# "CategoryName",
# "CategoryLevel1",
# "CategoryLevel2",
# "CategoryLevel3",
# "CouncilDistrictNumber",
# "SourceLevel1",
# "Neighborhood",
# "StatusType",
# "ServiceLevelName",
# "ZIP"

train_col$cat_heir.f <- factor(train_col$CategoryHierarchy)
is.factor(train_col$cat_heir.f)

train_col$cat_name.f <- factor(train_col$CategoryName)
is.factor(train_col$cat_name.f)

train_col$cat_1.f <- factor(train_col$CategoryLevel1)
is.factor(train_col$cat_1.f)

train_col$cat_2.f <- factor(train_col$CategoryLevel2)
is.factor(train_col$cat_2.f)

train_col$cat_3.f <- factor(train_col$CategoryLevel3)
is.factor(train_col$cat_3.f)

train_col$district.f <- factor(train_col$CouncilDistrictNumber)
is.factor(train_col$district.f)

train_col$source.f <- factor(train_col$SourceLevel1)
is.factor(train_col$source.f)

train_col$neighborhood.f <- factor(train_col$Neighborhood)
is.factor(train_col$neighborhood.f)

train_col$status.f <- factor(train_col$StatusType)
is.factor(train_col$status.f)

train_col$service.f <- factor(train_col$ServiceLevelName)
is.factor(train_col$service.f)

train_col$zip.f <- factor(train_col$ZIP)
is.factor(train_col$zip.f)

# convert into numeric values:
# train_col_numeric = train_col
# train_col_numeric %>% mutate_if(is.factor, as.numeric)

# convert with lapply function:
# https://stackoverflow.com/questions/47922184/convert-categorical-variables-to-numeric-in-r

train_col_numeric = train_col
i <- sapply(train_col_numeric, is.factor)
train_col_numeric[i] <- lapply(train_col_numeric[i], as.numeric)

# verify columns as numeric:
# str(train_col_numeric)
# head(train_col_numeric, 5)

cat("\n")
cat("*** summary statistics for numeric values ***")
cat("\n")

summary(train_col_numeric)

# save code in case prediction/validation is necessary:
# import test_data:
# test_data <- read.table(
#   './final-data-test.csv',
#   sep=',',
#   header=TRUE,
#   quote='',
#   strip.white=TRUE,
#   na.strings='?'
# )

# verify dim and drop NA; test_data:
# dim(test_data)
# na.omit(test_data)
# dim(test_data)
# head(test_data, 5)

# summary statistics; test_data:
# str(test_data)
# summary(test_data)

# reduce dataset to minimize runtime:
# test_reduced = test_data[1:1500,]

```

References:  
1. HES CSCI-E63c Midterm, HW5 code  
2. ISLR p.67; p-value  

Steps:  
1. Create histogram to evaluate distribution  
2. Create stacked bar histograms  
3. Evaluate trends from plots; identify possible trends  
4. Create plots for significant factors bsed on p-values  
5. Document observations below  

Observations:  
1. Create histograms for significant factors based on p-values  
2. Create stacked bar charts for significant factors based on p-values  
3. Stacked bar chart shows interaction between neighborhood and service level  

```{r p1.3}

# Create historgram for continous variables to evaluate distribution:

hist(
  train_col_numeric$district.f,
  main='Council District',
  col='purple',
  xlab='Continuous Variable - Council District',
  breaks=30
)

hist(
  train_col_numeric$service.f,
  main='311 Service Level',
  col='purple',
  xlab='Continuous Variable - 311 Service Level',
  breaks=10
)

# Create histogram, stacked bar chart; remaining variables
qplot_district = (qplot(
  train_col_numeric$district.f,
  binwidth = 1,
  fill=train_col_numeric$service.f,
  main='Outcome Variable - 311 Service Level')
  + scale_fill_manual(values=c('purple', 'red'))
  + theme(legend.position='top')
  + xlab('Predictor Variable - Council District Number')
)
qplot_district

```

References:  
1. HES CSCI-E63c Midterm, HW9, HW10, HW11 code  
2. ISLR p.67; data distribution  
3. ISLR p.76; data distribution    

Steps:  
1. Evaluate data distribution with contingency tables  
2. Evaluate distribution, then adjust for proportions  
3. Create contingency tables for select attributes   
4. Compare/evaluate results  
5. Document observations below   

Observations:  
1. Create contingency tables for significant factors based on p-values  
2. Contingency tables show distributions of variables and breaks them down by level  
3. In general, contingency tables are good for visualizing distributions by level  

```{r p1.4}

cat("\n")
cat("*** contingency table for neighborhood and source ***")
cat("\n")

# Create contingency table:
table(
  train_data$Neighborhood,
  train_data$SourceLevel1
)

cat("\n")
cat("*** contingency table for zipcode and source ***")
cat("\n")

# Create contingency table:
table(
  train_data$ZIP,
  train_data$SourceLevel1
)

```

References:  
1. HES CSCI-E63c Lecture 1, 3 notes; chi-squared test  
2. ISLR p.67; p-value and significance  

Steps:  
1. Calculate chi-squared test for categorical variables  
2. Evaluate/analyze results  
3. Document observations below  

Observations:  
1. Chi-squared test shows low p-values for categorial variables  
2. T-test for continous variables  
3. Chi-squared and t-test are a good method for evaluating significance  

Observations:  
1. Create plots for significant factors based on p-values  

```{r p1.5}

cat("\n")
cat("*** t-test for continous variables ***")
cat("\n")

# Chi-Squared test for continuous variables:
t.test(
  as.numeric(train_col$neighborhood.f),
  train_data$service.f
)

cat("\n")
cat("*** chi-squared test for categorical variables ***")
cat("\n")

# Chi-Squared test for categorical variables:
chisq.test(
  table(
    train_col$neighborhood.f,
    train_col$cat_1.f
  )
)

```

References:  
1. HES CSCI-E63c Midterm, HW6; PCA model  
2. ISLR p.230; PCA components  
3. ISLR p.233; PCA components  

Steps:  
1. Verify/prepare data for PCA plots; use dummy variables to setup factors  
2. Scale/fit data for PCA plots; plot for top contributors to variance  
3. Evaluate top contributors to variance  
4. Plot variance by first several PCA  

Observations:  
1. Use dummy variables to address muiple variable levels prior to PCA plot  
2. PCA calculations show top contributors of variance to the model  
3. PCA plot show interaction between neighborhood and service level  

```{r p1.6}

cat("\n")
cat("*** Plot variance for first several PCA ***")
cat("\n")

# train_scaled = train_data %>% mutate_if(is.numeric, scale)
# train_dummy = model.matrix(noyes ~., train_scaled)[,-1]

# Scale/dummy data prior to plot:
# train_numeric = as.numeric(train_col$zip.f)
# train_scaled = train_numeric %>% mutate_if(is.numeric, scale)
# train_dummy = model.matrix(noyes ~., train_scaled)[,-1]

# Scale/dummy data prior to plot:
train_scaled = train_col_numeric %>% mutate_if(is.numeric, scale)
train_dummy = model.matrix(Neighborhood ~., train_scaled)[,-1]

# prepare PCA components for plot:
prcomp_plot = prcomp(train_dummy)
plot(
  prcomp_plot,
  xlab='dimensions',
  col='purple'
)

cat("\n")
cat("*** Evaluate largest loading for first PC ***")
cat("\n")

sort(abs(prcomp_plot$rotation[,1]), decreasing=TRUE)[1]

cat("\n")
cat("*** Evaluate largest loading for second PC ***")
cat("\n")

sort(abs(prcomp_plot$rotation[,2]), decreasing=TRUE)[1]

cat("\n")
cat("*** Evaluate largest loading for third PC ***")
cat("\n")

sort(abs(prcomp_plot$rotation[,3]), decreasing=TRUE)[1]

cat("\n")
cat("*** Evaluate largest loading for fourth PC ***")
cat("\n")

sort(abs(prcomp_plot$rotation[,4]), decreasing=TRUE)[1]

cat("\n")
cat("*** Evaluate largest loading for fifth PC ***")
cat("\n")

sort(abs(prcomp_plot$rotation[,5]), decreasing=TRUE)[1]

cat("\n")
cat("*** Biplot: PC1 and PC2 (Scaled) ***")
cat("\n")

# create biplot of PCA components:
biplot(
  prcomp_plot,
  pc.biplot=TRUE,
  xlabs=rep('*', dim(prcomp_plot$x)[1]),
  col=c('red','purple')
)

cat("\n")
cat("*** PCA Plot ***")
cat("\n")

# create PCA plot:
plot(
  prcomp_plot$x[,1:2],
  main='PCA Plot: Neighborhood and Service Level',
  col=c(ifelse(train_col_numeric$Neighborhood== '>=10', 'red', 'purple')),
  cex=1.0,
  pch=ifelse(train_col_numeric$ServiceLevelName== '>=1', '*', '+')
)

```

References:  
1. ISLR p.67; p-value and significance  
2. ISLR p.286; logistic regression  
3. ISLR p.291; logistic regression usage  

Steps:  
1. Fit logistic regression model for predictor variables  
2. Evaluate/compare results of each variable  
3. Specifically, evaluate p-values of logistic regression output  
4. Evaluate results for association between predictor/outcome  

Observations:  
1. Most variables have low p-values, indicating significance as a predictor  
2. Use LR to fit categorical variables for additional analysis  

```{r p1.7}

cat("\n")
cat("*** LR: cat_1 ~ neighborhood ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel1~neighborhood.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_1 ~ district ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel1~district.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_1 ~ zipcode ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel1~zip.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_2 ~ neighborhood ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel2~neighborhood.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_2 ~ district ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel2~district.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_2 ~ zipcode ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel2~zip.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_3 ~ neighborhood ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel3~neighborhood.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_3 ~ district ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel3~district.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: cat_3 ~ zipcode ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  CategoryLevel3~zip.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: neighborhood ~ cat_1 ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  Neighborhood~cat_1.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: neighborhood ~ cat_2 ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  Neighborhood~cat_2.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: neighborhood ~ cat_3 ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  Neighborhood~cat_3.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: neighborhood ~ service level ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  Neighborhood~service.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: neighborhood ~ source ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  Neighborhood~source.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: zipcode ~ cat_1 ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  ZIP~cat_1.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: zipcode ~ cat_2 ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  ZIP~cat_2.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: zipcode ~ cat_3 ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  ZIP~cat_3.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: zipcode ~ service level ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  ZIP~service.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

cat("\n")
cat("*** LR: zipcode ~ source ***")
cat("\n")

# logistic regression model fit:
glm_train = glm(
  ZIP~source.f,
  data=train_col,
  family=binomial
)
summary(glm_train)

```

# Part 2 - Logistic Regression

References:  
1. HES CSCI-E63c HW2, HW9, HW10  
1. HW2 code; pairs plot  
2. HW9 code; pairs plot  
3. HW10 code; pairs plot  

Steps:  
1. Create pairs plot for scaled, numeric predictor variables  
2. Verify that columns are numeric and use scaled dataset  
3. Create plots; document observations below  
4. Use pairs plot to verify variables for additional analysis  

Observations:  
1. Scale values so that pairs plot can be correct associations  
2. Only numeric values selected for pairs plot  
3. Run pairs plot first before moving on with remaining analysis 

```{r p2.1}

# calculated here for analysis; comment out to reduce runtime
# create pairs plot of scaled numeric predictors:
# columns_is_numeric = unlist(lapply(train_reduced, is.numeric))
# numeric_cols = names(train_data)[columns_is_numeric]

# train_scaled_numeric = train_scaled %>% select_if(is.numeric)
# pairs(
#   train_scaled_numeric,
#   pch=25,
#   cex=0.8,
#   col=c(ifelse(train_scaled$source.f == '>1', 'purple', 'red')),
#   main='Pairs Plot - Source Level '
# )

```

References:  
1. HES CSCI-E63c Midterm, HW5  
2. Midterm-P2 and HW5; best subset variable selection  
3. ISLR p.244; best subset selection  
4. ISLR p.247; best subset selection  

Steps:  
1. Use variable selection to identify best predictors  
2. Use forward, backward and seq replacement methods  
3. Create metrics plot and individual plot for each method  
4. Evaluate/compare plot results  
5. Document observations below  

Observations:  
1. Each method returns the same variables and order of selection  
3. Results confirm previous findings/analysis/conjecture  
4. Significant variables will be useful for fitting other models  
5. Best subset plot visualizes results for evaluation  

```{r p2.2}

cat("\n")
cat("*** helper function for best subset selection ***")
cat("\n")

# helper function for best subset selection:
summaryMetrics <- NULL
whichAll <- list()
my_methods = c('backward', 'forward', 'seqrep')

for ( myMthd in my_methods ) {
  method_metrics = NULL
  rsRes <- regsubsets(
    Neighborhood~.,
    train_scaled,
    method=myMthd,
    nvmax=ncol(train_scaled)-1
  )
  summRes <- summary(rsRes)
  whichAll[[myMthd]] <- summRes$which

  for ( metricName in c('rsq','rss','adjr2','cp','bic') ) {
    summaryMetrics <- rbind(summaryMetrics,
      data.frame(method=myMthd,metric=metricName,
      nvars=1:length(summRes[[metricName]]),
      value=summRes[[metricName]]))
    method_metrics = rbind(method_metrics,
      data.frame(method=myMthd,metric=metricName,
      nvars=1:length(summRes[[metricName]]),
      value=summRes[[metricName]]))
  }
}

cat("\n")
cat("*** plot subset ***")
cat("\n")

# plot best subset:
ggplot(
    summaryMetrics,
    aes(x=nvars,y=value,shape=method,colour=method)
) + geom_path() + geom_point() + facet_wrap(~metric,scales='free') + theme(legend.position='top')

# plot best subset:
old.par <- par(mfrow=c(1,1),ps=9,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
  image(1:nrow(whichAll[[myMthd]]),
        1:ncol(whichAll[[myMthd]]),
        whichAll[[myMthd]],xlab="N(vars)",ylab="",
        xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
        col=c("white","purple"),main=myMthd)
  axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
  axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}

```

References:  
1. HES CSCI-E63c Midterm, HW5  
2. ISLR p.251; lasso/ridge regression  
3. HW5, midterm code; lasso regression  
4. HW5, midterm code; ridge regression  

Steps:  
1. Fit and plot lasso model  
2. Determine best lambda values  
3. Determine lambda value; 1 SD away  
4. Document observations below  

Observations:  
1. Make calculations using scaled data  
2. Additional calculations made to evaluate error rates  
3. Error rate also calculated for 1SD away  

```{r p2.3}

cat("\n")
cat("*** fit and plot lasso model ***")
cat("\n")

# fit and plot lasso model:
# x = model.matrix(noyes~., train_scaled_reduced)[,-1]
# y = train_scaled_reduced[,'noyes']

x = model.matrix(Neighborhood~., train_scaled)[,-1]
y = train_scaled[1:4973 ,'Neighborhood']

# lasso_fit_lr = glmnet(
#   x, y,
#   alpha=1,
#   family='binomial'
# )
# plot(lasso_fit_lr)

cat("\n")
cat("*** determine best lambda values ***")
cat("\n")

# determine best lambda values:
# cv_lasso_fit_lr = cv.glmnet(
#   x, y,
#   family='binomial',
#   type.measure='class'
# )
# plot(cv_lasso_fit_lr)

cat("\n")
cat("*** determine lambda value; 1 SD away ***")
cat("\n")

# determine best lambda values; 1 SD away:
# lowest_error_plus_one_sd_lambda = cv_lasso_fit_lr$lambda.1se

# evaluate which dashed lines is best:
# print(log(lowest_error_plus_one_sd_lambda))

cat("\n")
cat("*** lasso model prediction ***")
cat("\n")

# determine best lambda values; 1 SD away:
# predict(
#   lasso_fit_lr,
#   type='coefficients',
#   s=lowest_error_plus_one_sd_lambda
# )

```

References:  
1. HES CSCI-E63c Midterm, HW5, HW6; glm model  
2. HW9-P1 code; helper function to assess prediction quality  
3. HW9-P4 code; helper function for cross validation  
4. ISLR p.236; cross validation  

Steps:  
1. Create helper function to assess prediction quality  
2. Create helper function for cross validation  
3. Print and evaluate assessment results  
4. Plot and evaluate cross validation results  
5. Document results below  

Observations:  
1. Fit based on variables selected in previous sections  
2. Measures will be used to compare against other model fits  
3. Measures plot are a good method of evaluating metrics  

```{r p2.4}

cat("\n")
cat("*** helper function to predict model quality ***")
cat("\n")

# helper function to predict model quality:
assess_prediction = function(truth, predicted, print_results=FALSE) {
  # check for missing values (we are going to
  # compute metrics on non-missing values only)
  predicted = predicted[ ! is.na(truth) ]
  truth = truth[ ! is.na(truth) ]
  truth = truth[ ! is.na(predicted) ]
  predicted = predicted[ ! is.na(predicted) ]

  NotNa=length(truth)
  # how predictions align against known
  # training/testing outcomes:
  # TP/FP= true/false positives,
  # TN/FN=true/false negatives
  TP = sum(truth==1 & predicted==1)
  TN = sum(truth==0 & predicted==0)
  FP = sum(truth==0 & predicted==1)
  FN = sum(truth==1 & predicted==0)
  P = TP+FN # total number of positives in the truth data
  N = FP+TN # total number of negatives

  accuracy_pct = signif(sum(truth==predicted)*100/length(truth),3)
  error_rate_pct = 100-accuracy_pct
  sensitivity_pct = signif(100*TP/P,3)
  specificity_pct = signif(100*TN/N,3)
  precision_pct = signif(100*TP/(TP+FP),3)
  false_discovery_pct = signif(100*FP/(TP+FP),3)
  false_positive_rate_pct = signif(100*FP/N,3)

  if (print_results){
    cat("Total cases that are not NA: ",
    NotNa,"\n",sep="")

    # overall accuracy of the test: how many cases
    # (both positive and negative) we got right:
    cat("Correct predictions (accuracy): ",
      sum(truth==predicted),
      "(",accuracy_pct,"%)\n",sep="")
    cat("TPR (sensitivity)=TP/P: ", sensitivity_pct, "%\n", sep="")
    cat("TNR (specificity)=TN/N: ", specificity_pct, "%\n", sep="")
    cat("PPV (precision)=TP/(TP+FP): ", precision_pct, "%\n", sep="")
    cat("FDR (false discovery)=1-PPV: ", false_discovery_pct, "%\n", sep="")
    cat("FPR =FP/N=1-TNR: ", false_positive_rate_pct, "%\n", sep="")

    print('TP  TN  FP  FN')
    print(paste0(TP, ' ', TN, ' ', FP, ' ', FN))
  }

  return (list(NotNA=length(truth),
              accuracy_pct=accuracy_pct,
              error_rate_pct=error_rate_pct,
              sensitivity_pct=sensitivity_pct,
              specificity_pct=specificity_pct,
              precision_pct=precision_pct,
              false_discovery_pct=false_discovery_pct,
              false_positive_rate_pct=false_positive_rate_pct))
}

cat("\n")
cat("*** helper function for cross validation ***")
cat("\n")

# helper function for cross validation:
# xvalNoYes= function(data, nTries=20, kXval=5) {

# decrease parameters to reduce runtime:
xvalLR = function(data, nTries=5, kXval=3) {
  retRes = NULL
  # set.seed(63)
  for ( iTry in 1:nTries ) {
    # assign each observation to one of the kXval folds
    xvalFolds = sample(rep(1:kXval, length.out=nrow(data)))

      measures <- NULL
      for ( kFold in 1:kXval ) {
        train = data[xvalFolds!=kFold,]
        test = data[xvalFolds==kFold,]

        # *** significant factors based on p-values (1.6, logistic regression) ***
        # categorial = cle, kbc, gb, xxp, rao, at, fq
        # numerical = mt, zq, zf, ihj

        # use the variables selected by both glm and lasso
        glm_fit = glm(
          # noyes~cle+kbc+xxp+rao+at+fq,
          CategoryLevel1~neighborhood.f,
          data=train,
          family=binomial
        )

        # predict on the held-out fold
        glm_predict = predict(glm_fit, newdata=test, type='response')

        test_predict = ifelse(glm_predict > 0.5 , 1, 0)
        test_numeric = ifelse(test$CategoryLevel1 >= 0.5, 1, 0)

        test_assessment_measures = assess_prediction(
          test_numeric,
          test_predict,
          print_results=FALSE
        )

        # accumulate test measurements over all cross-validation folds:
        measures = rbind(measures, cbind(test_assessment_measures$accuracy_pct,
          test_assessment_measures$sensitivity_pct,
          test_assessment_measures$specificity_pct))
      }

      print(measures)
      measure_means = colMeans(measures)

      print(measure_means)
      retRes = rbind(retRes, data.frame(sim=iTry,
        accuracy_pct=measure_means[1],
        sensitivity_pct=measure_means[2],
        specificity_pct=measure_means[3])
      )

  }
  retRes
}

# decrease parameters to reduce runtime:
# number_of_folds = 5
number_of_folds = 5

# decrease parameters to reduce runtime:
# number_of_tries = 15
number_of_tries = 3

```

```{r final-p2.4A, results="hide"}

# reduce to smaller sample size to reduce runtime:
# train_scaled[1:5000,]
# df_output = xvalLR(
#   train_scaled,
#   kXval=number_of_folds,
#   nTries=number_of_tries
# )

```

```{r fig.width=9, fig.height=6, echo=FALSE}

cat("\n")
cat("*** cross validation plot ***")
cat("\n")

# cross validation plot:
# df_output_melted = melt(df_output, id.vars=c('sim'))
# p = ggplot(
#   df_output_melted,
#   aes(x=variable, y=value, colour=variable)
# ) + geom_boxplot()
# title = sprintf(
#   'Performance Measures Plot for LR; %d-fold Cross Validation',
#   number_of_folds
# )
# p + ggtitle(title) + xlab("Measure Type") + ylab("Measure Value %")

```

# Conclusion

Summarize findings once analysis has been completed.

*** SUMMARY ***
*** SUMMARY ***
*** SUMMARY ***

*** Summary Statistics - Full Dataset (~1.2M Rows x 27 Columns) ***  

'data.frame':	1225340 obs. of  27 variables:  
 $ X                    : num  -121 -122 -121 -122 -122 ...
 $ Y                    : num  38.6 38.5 38.4 38.6 38.5 ...
 $ OBJECTID             : int  6136 6137 6138 6139 6140 6141 6142 6143 6144 6145 ...
 $ ReferenceNumber      : Factor w/ 1130759 levels "160430-000040",..: 2999 3002 3003 3004 3005 3007 3006 3010 3008 3009 ...
 $ CategoryHierarchy    : Factor w/ 437 levels ":",": Code Enforcement",..: 342 340 326 318 323 326 339 363 326 71 ...
 $ CategoryLevel1       : Factor w/ 18 levels "","Animal care",..: 14 14 14 14 14 14 14 14 14 3 ...
 $ CategoryLevel2       : Factor w/ 48 levels "","Animal Cruelty (597)",..: 28 26 1 15 18 1 26 39 1 17 ...
 $ CategoryLevel3       : Factor w/ 10 levels "","Aggressive",..: 1 1 1 1 1 1 1 4 1 1 ...
 $ CategoryLevel4       : logi  NA NA NA NA NA NA ...
 $ CategoryLevel5       : logi  NA NA NA NA NA NA ...
 $ CategoryName         : Factor w/ 286 levels "","911 Transfer",..: 91 137 109 91 91 109 91 142 109 183 ...
 $ CouncilDistrictNumber: int  3 7 8 1 4 5 3 5 8 3 ...
 $ SourceLevel1         : Factor w/ 5 levels "","Email","Mobile App",..: 4 4 4 4 4 5 4 5 4 4 ...
 $ Neighborhood         : Factor w/ 130 levels "","Airport","Alhambra Triangle",..: 102 85 115 67 56 44 102 73 115 31 ...
 $ DateCreated          : Factor w/ 1118207 levels "2016-04-30T16:05:44.000Z",..: 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 ...
 $ DateUpdated          : Factor w/ 927449 levels "2016-04-30T16:46:53.000Z",..: 238837 146545 284898 238837 146543 241794 232773 238864 284900 295 ...
 $ DateClosed           : Factor w/ 772674 levels "","2016-05-30T18:53:03.000Z",..: 218275 136981 261213 218275 136981 221113 212237 218302 261213 1 ...
 $ StatusType           : Factor w/ 14 levels "Cancellation Completed",..: 4 3 4 4 3 4 4 4 4 8 ...
 $ SystemId             : int  13089 13091 13092 13095 13098 13100 13103 13107 13110 13112 ...
 $ ServiceLevelName     : Factor w/ 34 levels "","1 Hour-All Holidays-24/7",..: 13 13 1 1 1 1 13 1 1 29 ...
 $ Latitude             : num  38.6 38.5 38.4 38.6 38.5 ...
 $ Longitude            : num  -121 -122 -121 -122 -122 ...
 $ XCoord               : num  6706636 6692383 6730272 6700552 6697903 ...
 $ YCoord               : num  1988045 1940692 1925199 1993886 1953896 ...
 $ CrossStreet          : Factor w/ 11685 levels "","&","10TH AVE",..: 11552 9908 10313 1402 2119 6943 3935 3120 11242 6799 ...
 $ GlobalID             : Factor w/ 1225340 levels "00001d4c-8b09-4d05-a87c-46fbd73bc23d",..: 347721 686993 785273 361851 1165337 1078483 497589 933654 757256 194850 ...
 $ ZIP                  : Factor w/ 66 levels "","00000","11111",..: 53 51 32 54 42 42 53 40 43 36 ...

*** Summary Statistics - Subset Dataset (5k Rows x 8 Columns) ***  

'data.frame':	5000 obs. of  8 variables:  
 $ CategoryHierarchy    : Factor w/ 437 levels ":",": Code Enforcement",..: 342 340 326 318 323 326 339 363 326 71 ...
 $ CategoryName         : Factor w/ 286 levels "","911 Transfer",..: 91 137 109 91 91 109 91 142 109 183 ...
 $ CouncilDistrictNumber: int  3 7 8 1 4 5 3 5 8 3 ...
 $ SourceLevel1         : Factor w/ 5 levels "","Email","Mobile App",..: 4 4 4 4 4 5 4 5 4 4 ...
 $ Neighborhood         : Factor w/ 130 levels "","Airport","Alhambra Triangle",..: 102 85 115 67 56 44 102 73 115 31 ...
 $ StatusType           : Factor w/ 14 levels "Cancellation Completed",..: 4 3 4 4 3 4 4 4 4 8 ...
 $ ServiceLevelName     : Factor w/ 34 levels "","1 Hour-All Holidays-24/7",..: 13 13 1 1 1 1 13 1 1 29 ...
 $ ZIP                  : Factor w/ 66 levels "","00000","11111",..: 53 51 32 54 42 42 53 40 43 36 ...
                                         CategoryHierarchy               CategoryName  CouncilDistrictNumber     SourceLevel1 
 Solid Waste : Household Junk                     :1487    Household Junk      :1487   Min.   :1.000                   :   0  
 Solid Waste : Appliance and eWaste               : 259    Garbage             : 930   1st Qu.:3.000         Email     : 181  
 Solid Waste : Kick truck : Garbage               : 223    Lawn and Garden     : 365   Median :5.000         Mobile App: 284  
 Solid Waste : Illegal Dumping : Street / Sidewalk: 181    Recycle             : 359   Mean   :4.601         Phone Call:3926  
 Solid Waste : Replace Can : Garbage              : 152    Appliance and eWaste: 259   3rd Qu.:6.000         Web App   : 609  
 Solid Waste : Exchange Can : Garbage             : 150    Street / Sidewalk   : 181   Max.   :8.000                          
 (Other)                                          :2548    (Other)             :1419   NA's   :27                             
                   Neighborhood                   StatusType                       ServiceLevelName      ZIP      
 Valley Hi / North Laguna: 388   Completed             :3907                               :3355    95822  : 533  
 East Sacramento         : 302   In Progress           : 519   36 Hours-No Holidays-M/F-24h: 602    95823  : 486  
 Meadowview              : 296   Closed                : 440   7 Days-No Holidays-M/F-24h  : 211    95820  : 423  
 Pocket                  : 246   Cancelled             : 132   2 Hours-All Holidays-24x7   : 158    95831  : 403  
 Downtown                : 222   Pending               :   2   24 Hours-No Holidays-M/F-24h: 157    95838  : 351  
 South Natomas           : 178   Cancellation Completed:   0   7 Days-All Holidays-24x7    :  75    95833  : 310  
 (Other)                 :3368   (Other)               :   0   (Other)                     : 442    (Other):2494  